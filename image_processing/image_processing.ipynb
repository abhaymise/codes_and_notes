{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOmg9sOziQs4s63ODsN09Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhaymise/codes_and_notes/blob/main/image_processing/image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Feature Detection and Description\n",
        "**Keypoint Detection**: Algorithms like SIFT (Scale-Invariant Feature Transform), SURF (Speeded-Up Robust Features), and ORB (Oriented FAST and Rotated BRIEF).\n",
        "\n",
        "**Feature Matching**: Techniques for matching features between images, such as Brute Force Matcher and FLANN (Fast Library for Approximate Nearest Neighbors).\n",
        "\n",
        "### Image Segmentation\n",
        "**Threshold-Based Segmentation**: Simple and effective methods like global and adaptive thresholding.\n",
        "\n",
        "**Region-Based Segmentation**: Region growing, region splitting and merging.\n",
        "\n",
        "**Edge-Based Segmentation**: Techniques using edge detection algorithms like Canny.\n",
        "\n",
        "**Advanced Segmentation**: Watershed algorithm, GrabCut, and Deep Learning-based methods (e.g., Mask R-CNN).\n",
        "\n",
        "### Image Transformation and Registration\n",
        "**Geometric Transformations**: Affine transformations, homography, scaling, rotation, and translation.\n",
        "\n",
        "**Image Warping and Interpolation**: Bilinear and bicubic interpolation methods.\n",
        "\n",
        "**Image Registration**: Techniques for aligning images, such as feature-based and intensity-based methods.\n",
        "\n",
        "### Image Enhancement\n",
        "**Histogram Equalization**: Improving contrast using techniques like CLAHE (Contrast Limited Adaptive Histogram Equalization).\n",
        "\n",
        "**Noise Reduction**: Techniques like median filtering, Gaussian blurring, and bilateral filtering.\n",
        "\n",
        "**Sharpening**: Using high-pass filters and unsharp masking to enhance details.\n",
        "\n",
        "### Color Spaces and Color Models\n",
        "**Color Spaces**: Understanding RGB, HSV, LAB, and YUV color spaces.\n",
        "\n",
        "**Color Conversion**: Techniques for converting between different color spaces.\n",
        "\n",
        "### Object Detection and Recognition\n",
        "**Template Matching**: Basic method for detecting objects using a template.\n",
        "\n",
        "**Feature-Based Methods**: Using features like HOG (Histogram of Oriented Gradients) for object detection.\n",
        "\n",
        "### Image Classification\n",
        "**Traditional Methods**: Using techniques like Bag of Words (BoW) and Support Vector Machines (SVM).\n",
        "\n",
        "### Image Compression\n",
        "**Lossless Compression**: Techniques like PNG, GIF, and lossless JPEG.\n",
        "\n",
        "**Lossy Compression**: Techniques like JPEG and WebP.\n",
        "\n",
        "**Compression Algorithms**: Understanding the basics of algorithms like Huffman coding and Run-Length Encoding.\n",
        "\n",
        "\n",
        "###_Recommended Learning Resources_\n",
        "Books: \"Digital Image Processing\" by Gonzalez and Woods, \"Computer Vision: Algorithms and Applications\" by Richard Szeliski.\n",
        "Courses: \"Image and Video Processing\" on Coursera, \"Computer Vision\" by Stanford University (CS231n) available on YouTube.\n",
        "Online Platforms: Tutorials on OpenCV, PyTorch, and TensorFlow for practical implementations."
      ],
      "metadata": {
        "id": "J-lKtI3u2Y2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Image Processing Techniques\n",
        "**Image Filtering**:\n",
        "Understanding filters like\n",
        "  - Gaussian\n",
        "  - Sobel\n",
        "  - Laplacian\n",
        "  - for blurring, edge detection, and sharpening.\n",
        "\n",
        "**Thresholding**:\n",
        "Techniques like\n",
        "- Otsuâ€™s method,\n",
        "- adaptive thresholding,\n",
        "- binary thresholding.\n",
        "\n",
        "**Morphological Operations**:\n",
        "- Dilation\n",
        "- erosion\n",
        "- opening\n",
        "- closing\n",
        "-  their applications in noise removal and shape analysis.\n"
      ],
      "metadata": {
        "id": "wD_TxStd2veh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Color Spaces\n",
        "\n",
        "There are several color systems used to represent colors in images. Each color system has its own advantages and is suitable for different real-world applications. Here are some of the most common color systems and when to use them:\n",
        "\n",
        "### RGB (Red, Green, Blue):\n",
        "\n",
        "Usage: RGB is the most common color system used in digital displays and cameras. It represents colors by mixing varying intensities of red, green, and blue light.\n",
        "\n",
        "Applications: Web graphics, digital photography, computer monitors, television screens, and most color displays.\n",
        "\n",
        "## CMY (Cyan, Magenta, Yellow)\n",
        "\n",
        "Usage: CMY is a subtractive color model used in color printing. It represents colors by subtracting varying amounts of cyan, magenta, and yellow ink from white.\n",
        "\n",
        "Applications: Offset and digital printing, color mixing in paint and inkjet printers.\n",
        "\n",
        "##CMYK (Cyan, Magenta, Yellow, Key/Black)\n",
        "\n",
        "Usage: CMYK is an extension of CMY with an additional key (black) channel. It is used in color printing to produce a wider range of colors and improved text clarity.\n",
        "\n",
        "Applications: Professional color printing, magazines, brochures, and other print media.\n",
        "\n",
        "## HSV (Hue, Saturation, Value)\n",
        "\n",
        "Usage: HSV is a cylindrical color space that separates color information into hue (the type of color), saturation (the intensity or purity of color), and value (the brightness of the color).\n",
        "Applications: Image processing tasks where color manipulation is essential, such as color correction, object tracking, and computer vision.\n",
        "\n",
        "## HSL (Hue, Saturation, Lightness)\n",
        "\n",
        "Usage: HSL is similar to HSV but represents colors in a different way. It separates color information into hue, saturation, and lightness (the perceived brightness of the color).\n",
        "Applications: Graphic design, image editing, and color manipulation tasks.\n",
        "\n",
        "## YUV (Luma, Chroma)\n",
        "\n",
        "Usage: YUV separates color information into luma (brightness or intensity) and chroma (color difference). It is often used in video encoding and decoding to reduce bandwidth.\n",
        "\n",
        "Applications: Video compression, video broadcasting, and video playback.\n",
        "\n",
        "## Lab (CIELAB)\n",
        "\n",
        "Usage: Lab is a color space designed to be perceptually uniform, meaning that the numerical change in Lab values corresponds to the perceived change in color by humans. It is used for color calibration and color correction.\n",
        "\n",
        "Applications: Color measurement, quality control, and color matching in industries like textiles, printing, and product manufacturing.\n",
        "\n",
        "\n",
        "The choice of color system depends on the specific requirements of your application. When choosing a color system, consider factors like the intended output medium, color accuracy, and the perceptual properties of the colors. For instance, RGB is suitable for most digital displays, while CMYK is essential for professional printing. HSV and Lab are often used in color analysis and manipulation tasks, and YUV is important in video processing. Each color system has its unique advantages and is designed for specific use cases.\n",
        "\n"
      ],
      "metadata": {
        "id": "BGZKe3A64_DO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RTBYUB4p2jOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## what is alpha channel in images and what is it used for mostly in real life applications\n",
        "\n",
        "The alpha channel is a component of an image that represents the transparency or opacity of each pixel. It is commonly used in image formats that support transparency, such as PNG and some variants of TIFF, to indicate how opaque or translucent each pixel should be.\n",
        "\n",
        "The alpha channel ranges from 0 (completely transparent) to 255 (completely opaque) in most 8-bit per channel images, but it can have a wider range in higher bit-depth images.\n",
        "\n",
        "Here are some key aspects and real-life applications of the alpha channel in images:\n",
        "\n",
        "**Transparency**: The primary purpose of the alpha channel is to control the transparency of individual pixels. Pixels with an alpha value of 0 are fully transparent and do not contribute to the final image, while pixels with an alpha value of 255 are fully opaque.\n",
        "\n",
        "**Compositing**: The alpha channel is crucial for compositing multiple images or layers together. It allows you to overlay one image onto another while preserving the transparency information of each pixel. This is commonly used in graphic design, video editing, and visual effects to create complex scenes.\n",
        "\n",
        "**Anti-aliasing**: In computer graphics and digital image processing, anti-aliasing is used to smooth the jagged edges of objects. The alpha channel is employed to specify varying levels of transparency along the edges, creating a smoother transition from object to background.\n",
        "\n",
        "**Image Masking**: Alpha channels are often used as masks to define regions of interest within an image. These masks can be used for various purposes, such as isolating objects, applying filters selectively, or controlling the application of image effects.\n",
        "\n",
        "**Textures and Patterns**: The alpha channel can be used to define irregular patterns or textures that are partially transparent. This is valuable in computer games and 3D modeling to create realistic materials like glass or foliage.\n",
        "\n",
        "**Web Graphics**: In web design, transparent images with alpha channels are widely used for creating non-rectangular or irregularly shaped elements, such as logos or icons. This allows web developers to integrate graphics seamlessly into different web page designs.\n",
        "\n",
        "**Video Production**: In video production and post-production, the alpha channel is used for tasks like green screen or blue screen keying, where the background is made transparent to replace it with a different scene or visual element.\n",
        "\n",
        "**Image Compression**: Some image formats, such as WebP, use the alpha channel to achieve lossy compression with transparency, allowing for smaller file sizes while preserving image quality.\n",
        "\n",
        "In summary, the alpha channel is a critical component in digital imaging, enabling the representation of transparency and controlling the compositing of multiple elements. It finds applications in a wide range of fields, including graphic design, video editing, web development, and 3D modeling, where the precise control of transparency is essential for creating compelling visuals.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0tkFgvm-6y-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bitwise operations on images\n",
        "\n",
        "Bitwise operations on images involve manipulating the pixel values of two or more images using binary logic operations. These operations are often used for various image processing tasks such as creating masks, combining or isolating specific channels, and performing bitwise comparisons. In OpenCV and similar libraries, bitwise operations are typically performed on grayscale or binary images.\n",
        "\n",
        "The common bitwise operations used in image processing are:\n",
        "\n",
        "#### AND Operation (cv2.bitwise_and):\n",
        "\n",
        "The bitwise AND operation takes two input images and returns an output image where each pixel is set to 255 (white) only if the corresponding pixels in both input images are also white (i.e., have a value of 255).\n",
        "This operation is often used to create a mask that isolates specific regions or objects in an image.\n",
        "\n",
        "#### OR Operation (cv2.bitwise_or):\n",
        "\n",
        "The bitwise OR operation takes two input images and returns an output image where each pixel is set to 255 if at least one of the corresponding pixels in the input images is white.\n",
        "This operation can be used to combine masks or regions of interest.\n",
        "\n",
        "#### XOR Operation (cv2.bitwise_xor):\n",
        "\n",
        "The bitwise XOR operation takes two input images and returns an output image where each pixel is set to 255 if the corresponding pixels in the input images have different values (one white and one black).\n",
        "XOR is often used to find the difference or non-overlapping regions between two masks.\n",
        "\n",
        "#### NOT Operation (cv2.bitwise_not):\n",
        "\n",
        "The bitwise NOT operation takes a single input image and inverts the pixel values. Pixels that were white become black, and vice versa.\n",
        "\n",
        "\n",
        "### Applications\n",
        "\n",
        "- Masking and Region Selection\n",
        "- selective coloring\n",
        "- Image Arithmetic and Manipulation\n",
        "- Overlaying Images with Transparency"
      ],
      "metadata": {
        "id": "EC2NLEry8YPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Arithmetic and Manipulation\n",
        "Bitwise operations can also be used for basic arithmetic operations on images, such as adding or subtracting pixel values between images.\n",
        "\n",
        "Example: Adding Two Images\n",
        "\n",
        "``` python\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load two images\n",
        "image1 = cv2.imread('image1.jpg')\n",
        "image2 = cv2.imread('image2.jpg')\n",
        "\n",
        "# Ensure both images are of the same size\n",
        "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
        "\n",
        "# Add images using bitwise operations\n",
        "result = cv2.add(image1, image2)\n",
        "\n",
        "# Display and save the result\n",
        "cv2.imshow('Added Image', result)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "7-wEbd1YMLJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overlaying Images with Transparency\n",
        "Bitwise operations can be used to overlay images with varying levels of transparency, allowing for subtle blending effects.\n",
        "\n",
        "**Example**: Overlaying with Transparency\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load two images\n",
        "image1 = cv2.imread('image1.jpg')\n",
        "image2 = cv2.imread('image2.jpg')\n",
        "\n",
        "# Ensure both images are of the same size\n",
        "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
        "\n",
        "# Create a mask for the overlay (e.g., with a gradient)\n",
        "mask = np.zeros_like(image1[:, :, 0])\n",
        "mask[:, :mask.shape[1]//2] = 255  # Gradient mask from left to right\n",
        "\n",
        "# Apply the mask with transparency using bitwise_and\n",
        "result = cv2.bitwise_or(cv2.bitwise_and(image1, image1, mask=cv2.bitwise_not(mask)),\n",
        "                        cv2.bitwise_and(image2, image2, mask=mask))\n",
        "\n",
        "# Display and save the result\n",
        "cv2.imshow('Overlayed Image', result)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "1AwZZQbWL1ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking and Region Selection\n",
        "Bitwise operations are commonly used to create and manipulate masks, which are essential for selecting specific regions of an image for editing or processing.\n",
        "\n",
        "Example: Creating a Circular Mask\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load an image\n",
        "image = cv2.imread('input_image.jpg')\n",
        "\n",
        "# Create a circular mask (white circle on black background)\n",
        "mask = np.zeros_like(image[:, :, 0])\n",
        "circle_center = (150, 150)\n",
        "circle_radius = 100\n",
        "cv2.circle(mask, circle_center, circle_radius, (255), -1)\n",
        "\n",
        "# Apply the mask to the image using bitwise_and\n",
        "masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "# Display and save the result\n",
        "cv2.imshow('Masked Image', masked_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "1QpNiLn6Le0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selective coloring\n",
        "\n",
        "To achieve selective coloring using OpenCV, where the object of interest (in this case, a box) remains in color while the rest of the image is converted to grayscale, we can follow a similar approach to traditional image editing techniques. Here's a step-by-step example using Python and OpenCV:\n",
        "\n",
        "Step-by-Step Implementation:\n",
        "\n",
        "### Load the Image:\n",
        "\n",
        "Load the image containing the object of interest (box) using OpenCV.\n",
        "\n",
        "### Convert Image to Grayscale:\n",
        "\n",
        "Convert the entire image to grayscale using OpenCV.\n",
        "\n",
        "### Create a Mask for the Object of Interest:\n",
        "\n",
        "Create a binary mask where the box is represented by white (255) and the rest of the image by black (0).\n",
        "\n",
        "### Apply the Mask to Keep the Object in Color:\n",
        "\n",
        "Use the bitwise AND operation to combine the grayscale image with the original color image, using the mask to keep the box in color while the rest of the image remains grayscale.\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image_with_box.jpg')\n",
        "\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Create a binary mask for the object of interest (assuming a rectangular box)\n",
        "# Replace with actual object detection or segmentation for real-world scenarios\n",
        "mask = np.zeros_like(gray)\n",
        "box_area = (50, 50, 200, 200)  # Define box region (x, y, width, height)\n",
        "mask[box_area[1]:box_area[1]+box_area[3], box_area[0]:box_area[0]+box_area[2]] = 255\n",
        "\n",
        "# Convert mask to 3-channel format (for bitwise operations)\n",
        "mask_color = cv2.merge([mask, mask, mask])\n",
        "\n",
        "# Use bitwise AND to apply the mask and keep the box in color\n",
        "result = cv2.bitwise_and(image, mask_color)\n",
        "\n",
        "# Combine with the grayscale image to keep the box in color and rest in grayscale\n",
        "result_gray = cv2.bitwise_and(gray, cv2.bitwise_not(mask))\n",
        "result_colored = cv2.merge([result_gray, result_gray, result_gray])  # Convert grayscale to 3-channel\n",
        "\n",
        "final_image = cv2.add(result, result_colored)\n",
        "\n",
        "# Display and save the result\n",
        "cv2.imshow('Selective Coloring', final_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "Step 1: Load the image using cv2.imread.\n",
        "\n",
        "Step 2: Convert the loaded image to grayscale using cv2.cvtColor.\n",
        "\n",
        "Step 3: Create a binary mask (mask) that identifies the region of interest (box) by setting pixels inside the box to white (255) and pixels outside the box to black (0).\n",
        "\n",
        "Step 4: Convert the binary mask to a 3-channel format (mask_color) and use bitwise AND (cv2.bitwise_and) to combine it with the original color image (image). This operation keeps the box in color while turning the rest of the image grayscale.\n",
        "\n",
        "Step 5: Create a grayscale version of the original image (result_gray) using bitwise operations and convert it to a 3-channel format.\n",
        "\n",
        "Step 6: Combine the selectively colored box (result) with the grayscale image (result_gray) using cv2.add to get the final selective coloring effect.\n",
        "\n",
        "Step 7: Display the final result using cv2.imshow and handle user interaction (cv2.waitKey and cv2.destroyAllWindows)."
      ],
      "metadata": {
        "id": "vVobLNMmJS6q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-RgsNYLI-ro"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}